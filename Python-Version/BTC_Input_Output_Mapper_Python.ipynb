{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc1-W22gazIf"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "import numpy as np\n",
        "from typing import List\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([1, 2], dtype=np.float32)\n",
        "outputs = np.array([1, 2, 3], dtype=np.float32)"
      ],
      "metadata": {
        "id": "EUAJ_FwYa4lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_partitions_matrix(arr: np.ndarray) -> np.ndarray:\n",
        "    arr = arr.astype(np.float32)\n",
        "    n = len(arr)\n",
        "\n",
        "    def generate_index_partitions(n: int) -> List[List[List[int]]]:\n",
        "        \"\"\"Generate all set partitions of indices [0, ..., n-1]\"\"\"\n",
        "        if n == 0:\n",
        "            return [[]]\n",
        "        prev_partitions = generate_index_partitions(n - 1)\n",
        "        new_partitions = []\n",
        "        for partition in prev_partitions:\n",
        "            new_partitions.append(partition + [[n - 1]])  # New block\n",
        "            for i in range(len(partition)):\n",
        "                copy = [block.copy() for block in partition]\n",
        "                copy[i].append(n - 1)\n",
        "                new_partitions.append(copy)\n",
        "        return new_partitions\n",
        "\n",
        "    # Generate index partitions\n",
        "    index_partitions = generate_index_partitions(n)\n",
        "\n",
        "    # Build float32 rows with 0.0 separators, last column is number of sets\n",
        "    rows = []\n",
        "    for partition in index_partitions:\n",
        "        row = []\n",
        "        for block in partition:\n",
        "            row.extend(arr[block])\n",
        "            row.append(0.0)  # Separator between blocks\n",
        "        rows.append((np.array(row, dtype=np.float32), len(partition)))\n",
        "\n",
        "    # Determine max row length (excluding count), and add 1 column for count\n",
        "    max_len = max(len(r[0]) for r in rows)\n",
        "    total_columns = max_len + 1\n",
        "\n",
        "    # Allocate final padded matrix\n",
        "    matrix = np.zeros((len(rows), total_columns), dtype=np.float32)\n",
        "    for i, (data_row, num_sets) in enumerate(rows):\n",
        "        matrix[i, :len(data_row)] = data_row\n",
        "        matrix[i, -1] = float(num_sets)  # Set count in the last column\n",
        "\n",
        "    return matrix"
      ],
      "metadata": {
        "id": "lm1hbZyRbHr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_partitions = generate_partitions_matrix(inputs)\n",
        "output_partitions = generate_partitions_matrix(outputs)"
      ],
      "metadata": {
        "id": "0oQXl0mbbMSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_partitions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGNLBN5fVfIN",
        "outputId": "b1c56492-d89c-4cb5-ccd8-c82709e7bb5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 2., 0., 2.],\n",
              "       [1., 2., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of both arrays and size of matrix to store results in for chunked processing\n",
        "DEPTH = len(inputs) * len(outputs) # nach hinten\n",
        "SIZE = 100000 # nach unten\n",
        "WIDTH = 2 * (len(inputs) + len(outputs)) # zur Seite\n",
        "\n",
        "# Define the CUDA kernel (GPU function)\n",
        "# inputs should be potential_mappings_inputs\n",
        "# outputs should be potential_mappings_outputs\n",
        "@cuda.jit\n",
        "def gpu_function(inputs, outputs, result):\n",
        "    row_idx = cuda.grid(1)  # each thread processes one \"row\" (SIZE)\n",
        "\n",
        "    depth = result.shape[0]   # DEPTH\n",
        "    size = result.shape[1]    # SIZE\n",
        "    width = result.shape[2]   # WIDTH\n",
        "\n",
        "    rows_inputs = inputs.shape[0]   # ROWS\n",
        "    width_inputs = inputs.shape[1]    # WIDTH\n",
        "\n",
        "    rows_outputs = outputs.shape[0]   # ROWS\n",
        "    width_outputs = outputs.shape[1]    # WIDTH\n",
        "\n",
        "    if row_idx < size:\n",
        "      # Thread logic for GPU\n",
        "      # result[d, row_idx, w] zum Schreiben von Werten\n",
        "\n",
        "      result[:, row_idx, :] = 2\n",
        "      result[:, row_idx, :] = 3"
      ],
      "metadata": {
        "id": "Vn2C80HlbQJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Iterate over both matrices to find potential valid mappings that have the same amount of partitions\n",
        "# Store them in two new matrices such that same rows refer to a potential valid mapping\n",
        "#for row in input_partitions:\n",
        "#  for row in output_partitions:\n",
        "input_columns = input_partitions.shape[1]\n",
        "output_columns = output_partitions.shape[1]\n",
        "\n",
        "potential_mappings_inputs = np.zeros((SIZE, input_columns), dtype=np.float32)\n",
        "potential_mappings_outputs = np.zeros((SIZE, output_columns), dtype=np.float32)\n",
        "\n",
        "result = np.zeros((DEPTH, SIZE, WIDTH), dtype=np.float32)\n",
        "\n",
        "counter = 0\n",
        "for ip in input_partitions:\n",
        "  for op in output_partitions:\n",
        "      if ip[input_columns-1] == op[output_columns-1]:\n",
        "        potential_mappings_inputs[counter] = ip\n",
        "        potential_mappings_outputs[counter] = op\n",
        "        counter += 1\n",
        "        if counter >= SIZE: # Maximum array size reached\n",
        "          # Copy data to GPU\n",
        "          d_inputs = cuda.to_device(potential_mappings_inputs)\n",
        "          d_outputs = cuda.to_device(potential_mappings_outputs)\n",
        "          d_result = cuda.device_array_like(result)\n",
        "\n",
        "          # Configure the blocks\n",
        "          threads_per_block = 256\n",
        "          blocks_per_grid = (SIZE + threads_per_block - 1) // threads_per_block\n",
        "\n",
        "          # Launch the kernel\n",
        "          gpu_function[blocks_per_grid, threads_per_block](d_inputs, d_outputs, d_result)\n",
        "\n",
        "          # Copy result back to host\n",
        "          d_result.copy_to_host(result)\n",
        "\n",
        "          #----------------------------------\n",
        "          print(\"Fertig...\")\n",
        "\n",
        "          print(result)\n",
        "\n",
        "          time.sleep(50)\n",
        "\n",
        "          # Clear arrays\n",
        "          potential_mappings_inputs.fill(0)\n",
        "          potential_mappings_outputs.fill(0)\n",
        "\n",
        "          # Reset counter\n",
        "          counter = 0\n",
        "\n",
        "# Copy data to GPU\n",
        "d_inputs = cuda.to_device(potential_mappings_inputs)\n",
        "d_outputs = cuda.to_device(potential_mappings_outputs)\n",
        "d_result = cuda.device_array_like(result)\n",
        "\n",
        "# Configure the blocks\n",
        "threads_per_block = 256\n",
        "blocks_per_grid = (SIZE + threads_per_block - 1) // threads_per_block\n",
        "\n",
        "# Launch the kernel\n",
        "gpu_function[blocks_per_grid, threads_per_block](d_inputs, d_outputs, d_result)\n",
        "\n",
        "# Copy result back to host\n",
        "d_result.copy_to_host(result)\n",
        "\n",
        "#----------------------------------\n",
        "print(\"Fertig...\")\n",
        "\n",
        "print(result)\n",
        "\n",
        "time.sleep(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "_RuK1SeWbTnQ",
        "outputId": "230e692f-fdc8-428b-c885-51bd298dbe52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fertig...\n",
            "[[[3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  ...\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]]\n",
            "\n",
            " [[3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  ...\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]]\n",
            "\n",
            " [[3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  ...\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]]\n",
            "\n",
            " [[3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  ...\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]\n",
            "  [3. 3. 3. ... 3. 3. 3.]]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-8a82a74bbe3d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}